{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Seasons_Stats.csv').fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_data = pd.read_csv('mvp_voting_stats.csv').fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2018 = pd.read_csv('current_season_stats_12_03.csv').fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>...</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>Paul Arizin*</td>\n",
       "      <td>SF</td>\n",
       "      <td>23.0</td>\n",
       "      <td>PHW</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>Cliff Barker</td>\n",
       "      <td>SG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>INO</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>490</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>Don Barksdale*</td>\n",
       "      <td>PF</td>\n",
       "      <td>28.0</td>\n",
       "      <td>BLB</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>491</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>Leo Barnhorst</td>\n",
       "      <td>SF</td>\n",
       "      <td>27.0</td>\n",
       "      <td>INO</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>492</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>Elmer Behnke</td>\n",
       "      <td>C</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MLH</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Year          Player Pos   Age   Tm     G   GS      MP   PER  \\\n",
       "0         488  1952.0    Paul Arizin*  SF  23.0  PHW  66.0  0.0  2939.0  25.5   \n",
       "1         489  1952.0    Cliff Barker  SG  31.0  INO  44.0  0.0   494.0  10.8   \n",
       "2         490  1952.0  Don Barksdale*  PF  28.0  BLB  62.0  0.0  2014.0  15.8   \n",
       "3         491  1952.0   Leo Barnhorst  SF  27.0  INO  66.0  0.0  2344.0  15.9   \n",
       "4         492  1952.0    Elmer Behnke   C  22.0  MLH   4.0  0.0    55.0   7.8   \n",
       "\n",
       "    ...      FT%  ORB  DRB    TRB    AST  STL  BLK  TOV     PF     PTS  \n",
       "0   ...    0.818  0.0  0.0  745.0  170.0  0.0  0.0  0.0  250.0  1674.0  \n",
       "1   ...    0.588  0.0  0.0   81.0   70.0  0.0  0.0  0.0   56.0   126.0  \n",
       "2   ...    0.691  0.0  0.0  601.0  137.0  0.0  0.0  0.0  230.0   781.0  \n",
       "3   ...    0.652  0.0  0.0  430.0  255.0  0.0  0.0  0.0  196.0   820.0  \n",
       "4   ...    0.571  0.0  0.0   17.0    4.0  0.0  0.0  0.0   13.0    16.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>First</th>\n",
       "      <th>Pts_Won</th>\n",
       "      <th>Pts_Max</th>\n",
       "      <th>Share</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>PTS</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>FGr</th>\n",
       "      <th>ThreePr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>WS</th>\n",
       "      <th>WSper48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>Kareem Abdul-Jabbar</td>\n",
       "      <td>32</td>\n",
       "      <td>LAL</td>\n",
       "      <td>147.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.665</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>24.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.765</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>2</td>\n",
       "      <td>Julius Erving</td>\n",
       "      <td>29</td>\n",
       "      <td>PHI</td>\n",
       "      <td>31.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>221</td>\n",
       "      <td>0.143</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.787</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>George Gervin</td>\n",
       "      <td>27</td>\n",
       "      <td>SAS</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.086</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.852</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>4</td>\n",
       "      <td>Larry Bird</td>\n",
       "      <td>23</td>\n",
       "      <td>BOS</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.068</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>21.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.836</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980</td>\n",
       "      <td>5T</td>\n",
       "      <td>Tiny Archibald</td>\n",
       "      <td>31</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.009</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.830</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Rank               Player  Age   Tm  First  Pts_Won  Pts_Max  Share  \\\n",
       "0  1980    1  Kareem Abdul-Jabbar   32  LAL  147.0    147.0      221  0.665   \n",
       "1  1980    2        Julius Erving   29  PHI   31.5     31.5      221  0.143   \n",
       "2  1980    3        George Gervin   27  SAS   19.0     19.0      221  0.086   \n",
       "3  1980    4           Larry Bird   23  BOS   15.0     15.0      221  0.068   \n",
       "4  1980   5T       Tiny Archibald   31  BOS    2.0      2.0      221  0.009   \n",
       "\n",
       "    G   ...      PTS   TRB  AST  STL  BLK    FGr  ThreePr    FTr    WS  \\\n",
       "0  82   ...     24.8  10.8  4.5  1.0  3.4  0.604    0.000  0.765  14.8   \n",
       "1  78   ...     26.9   7.4  4.6  2.2  1.8  0.519    0.200  0.787  12.5   \n",
       "2  78   ...     33.1   5.2  2.6  1.4  1.0  0.528    0.314  0.852  10.6   \n",
       "3  82   ...     21.3  10.4  4.5  1.7  0.6  0.474    0.406  0.836  11.2   \n",
       "4  80   ...     14.1   2.5  8.4  1.3  0.1  0.482    0.222  0.830   8.9   \n",
       "\n",
       "   WSper48  \n",
       "0    0.227  \n",
       "1    0.213  \n",
       "2    0.173  \n",
       "3    0.182  \n",
       "4    0.148  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter = data[\"Year\"] >= 1980\n",
    "data = data[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18927"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mvps = {2017:'Russell Westbrook', 2016:'Stephen Curry', 2015:'Stephen Curry', 2014:'Kevin Durant', 2013:'LeBron James',2012:'LeBron James',2011:'Derrick Rose',2010:'LeBron James',2009:'LeBron James',2008:'Kobe Bryant',2007:'Dirk Nowitzki',2006:'Steve Nash',2005:'Steve Nash',2004:'Kevin Garnett',2003:'Tim Duncan',2002:'Tim Duncan',2001:'Allen Iverson',2000:'''Shaquille O'Neal''',1999:'Karl Malone',1998:'Michael Jordan',1997:'Karl Malone',1996:'Michael Jordan',1995:'David Robinson',1994:'Hakeem Olajuwon',1993:'Charles Barkley',1992:'Michael Jordan',1991:'Michael Jordan',1990:'Magic Johnson',1989:'Magic Johnson',1988:'Michael Jordan',1987:'Magic Johnson',1986:'Larry Bird',1985:'Larry Bird',1984:'Larry Bird',1983:'Moses Malone',1982:'Moses Malone',1981:'Julius Erving',1980:'Kareem Abdul-Jabbar'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Player = namedtuple('Player', ['Year','Name', 'Pos', 'Games','MP','PER','TSr','ThreePAr','FTRate','ORBr','DRBr','TRBr','ASTr','STLr','BLKr','TOVr','USGr','OWS','DWS','WS','WSper48','OBPM','DBPM','BPM','VORP','FG','FGA','FGr','ThreeP','ThreePA','ThreePr','TwoP','TwoPA','TwoPr','eFGr','FT','FTA','FTr','ORB','DRB','TRB','AST','STL','BLK','TOV','PF','PTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Since row.FT%, row.3p, etc is not valid because a valid string cannot have % in it or start with a number, and I don't know how to escape it in this case, I have to use their indexes as below.\n",
    "#11:TS%, 12:3PAr,14:ORB%,15:DRB%,16:TRB%,17:AST%,18:STL%,19:BLK%,20:TOV%,21:USG%,26:WS/48,34:FG%,35:3P,36:3PA,37:3P%,38:2P,39:2PA,40:2P%,41:eFG%,44:FT%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18927"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine players who played for multiple teams in the same season\n",
    "data_refined = []\n",
    "y = []\n",
    "mul_team_player = None\n",
    "for row in data.itertuples():\n",
    "    # get rid of the * at the end of some players' names\n",
    "    player_name = None\n",
    "    if row.Player[-1] == '*':\n",
    "        player_name = row.Player[0:-1]   \n",
    "    else:\n",
    "        player_name = row.Player\n",
    "    \n",
    "    # when the current player is new or did not play for multiple teams in the same season\n",
    "    if mul_team_player != player_name:\n",
    "        \n",
    "        data_refined.append(Player(row.Year,player_name,row.Pos,row.G,row.MP,row.PER,row[11],row[12],row.FTr,row[14],row[15],row[16],row[17],row[18],row[19],row[20],row[21],row.OWS,row.DWS,row.WS,row[26],row.OBPM,row.DBPM,row.BPM,row.VORP,row.FG,row.FGA,row[34],row[35],row[36],row[37],row[38],row[39],row[40],row[41],row.FT,row.FTA,row[44],row.ORB,row.DRB,row.TRB,row.AST,row.STL,row.BLK,row.TOV,row.PF,row.PTS))\n",
    "        # if the team is TOT: the current play has played for multiple teams\n",
    "        if row.Tm == \"TOT\":\n",
    "            mul_team_player = row.Player # mark the name of mul_team_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15578"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Player(Year=1980.0, Name='Kareem Abdul-Jabbar', Pos='C', Games=82.0, MP=3143.0, PER=25.300000000000001, TSr=0.63900000000000001, ThreePAr=0.001, FTRate=0.34399999999999997, ORBr=7.2000000000000002, DRBr=22.199999999999999, TRBr=15.4, ASTr=16.5, STLr=1.2, BLKr=4.5999999999999996, TOVr=15.699999999999999, USGr=24.100000000000001, OWS=9.5, DWS=5.2999999999999998, WS=14.800000000000001, WSper48=0.22699999999999998, OBPM=4.0, DBPM=2.7000000000000002, BPM=6.7000000000000002, VORP=6.7999999999999998, FG=835.0, FGA=1383.0, FGr=0.60399999999999998, ThreeP=0.0, ThreePA=1.0, ThreePr=0.0, TwoP=835.0, TwoPA=1382.0, TwoPr=0.60399999999999998, eFGr=0.60399999999999998, FT=364.0, FTA=476.0, FTr=0.76500000000000001, ORB=190.0, DRB=696.0, TRB=886.0, AST=371.0, STL=81.0, BLK=280.0, TOV=297.0, PF=216.0, PTS=2034.0)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_refined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some names ends with \"*\", so get rid of that. Get X(features) data and y(labels).\n",
    "X_data = []\n",
    "X_data_reduced1 = []\n",
    "X_data_reduced2 = []\n",
    "y_data = []\n",
    "for d in data_refined:\n",
    "    name = d.Name\n",
    "    if name[-1] == '*':\n",
    "        name = name[0:-1]\n",
    "    if mvps[int(d.Year)] == name:\n",
    "        y_data.append(1)\n",
    "    else:\n",
    "        y_data.append(0)\n",
    "        \n",
    "    #NOTE: Make sure to change the features here\n",
    "    features1 = [d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "    X_data.append(features1) \n",
    "    #Ignore\n",
    "    features2 = [d.Games,d.MP,d.PER,d.TSr,d.ASTr,d.USGr,d.OWS,d.WS,d.WSper48,d.OBPM,d.BPM,d.VORP,d.FT,d.ORB,d.PF]\n",
    "    X_data_reduced1.append(features2)\n",
    "    #The 6 features\n",
    "    features3 = [d.PER,d.TSr,d.USGr,d.WS,d.BPM,d.VORP]\n",
    "    X_data_reduced2.append(features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From 1980-2017, 38 years so 38 mvps\n",
    "sum(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_training = X_data[:len(X_data)*3//4]\n",
    "y_training = y_data[:len(X_data)*3//4]\n",
    "X_testing = X_data[len(X_data)*3//4:]\n",
    "y_testing = y_data[len(X_data)*3//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For normalization, use if needed\n",
    "std_scale = preprocessing.StandardScaler().fit(X_training)\n",
    "X_training_std = std_scale.transform(X_training)\n",
    "X_testing_std = std_scale.transform(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_training_reduced1 = X_data_reduced1[:len(X_data_reduced1)*3//4]\n",
    "X_testing_reduced1 = X_data_reduced1[len(X_data_reduced1)*3//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3895"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pred, labels):\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    PRECISION = 0\n",
    "    RECALL = 0\n",
    "    for (a,b) in zip(pred, labels):\n",
    "        if (a==True and b==True):\n",
    "            TP = TP+1\n",
    "        elif (a==True and b==False):\n",
    "            FP = FP+1\n",
    "        elif (a==False and b==True):\n",
    "            FN = FN+1\n",
    "        elif (a==False and b==False):\n",
    "            TN = TN+1\n",
    "    \n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    BER = 1-(TPR+TNR)/2\n",
    "    if TP+FP == 0:\n",
    "        PRECISION = 0\n",
    "    else:\n",
    "        PRECISION = TP / (TP+FP)\n",
    "    if TP+FN == 0:\n",
    "        RECALL = 0\n",
    "    else:\n",
    "        RECALL = TP / (TP+FN)\n",
    "    print(\"Statistics for our training model: \")\n",
    "    print(\"\\nTrue positives: \" + str(TP))\n",
    "    print(\"True negatives: \" + str(TN))\n",
    "    print(\"False positives: \" + str(FP))\n",
    "    print(\"False negatives: \" + str(FN))\n",
    "    print(\"\\nAccuracy: \" + str((TP + TN)/len(pred)))\n",
    "    print(\"BER is \" + str(BER))\n",
    "    print(\"Precision: \" + str(PRECISION))\n",
    "    print(\"Recall: \" + str(RECALL))\n",
    "    return PRECISION,RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use for graph, only return precision and recall without printing out results\n",
    "def evaluate_noprint(pred, labels):\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    PRECISION = 0\n",
    "    RECALL = 0\n",
    "    for (a,b) in zip(pred, labels):\n",
    "        if (a==True and b==True):\n",
    "            TP = TP+1\n",
    "        elif (a==True and b==False):\n",
    "            FP = FP+1\n",
    "        elif (a==False and b==True):\n",
    "            FN = FN+1\n",
    "        elif (a==False and b==False):\n",
    "            TN = TN+1\n",
    "    \n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    BER = 1-(TPR+TNR)/2\n",
    "    if TP+FP == 0:\n",
    "        PRECISION = 0\n",
    "    else:\n",
    "        PRECISION = TP / (TP+FP)\n",
    "    if TP+FN == 0:\n",
    "        RECALL = 0\n",
    "    else:\n",
    "        RECALL = TP / (TP+FN)\n",
    "\n",
    "    return PRECISION,RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for our training model: \n",
      "\n",
      "True positives: 8\n",
      "True negatives: 3862\n",
      "False positives: 25\n",
      "False negatives: 0\n",
      "\n",
      "Accuracy: 0.993581514762516\n",
      "BER is 0.003215847697453089\n",
      "Precision: 0.24242424242424243\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Use for classification\n",
    "clf_RFC = RandomForestClassifier(n_estimators=100,max_depth=3, random_state=2,class_weight = {0:1,1:70})\n",
    "clf_RFC.fit(X_training, y_training)\n",
    "pred_RFC = clf_RFC.predict(X_testing)\n",
    "evaluate(pred_RFC, y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3836"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_testing_reduced1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for our training model: \n",
      "\n",
      "True positives: 8\n",
      "True negatives: 3851\n",
      "False positives: 36\n",
      "False negatives: 0\n",
      "\n",
      "Accuracy: 0.9907573812580232\n",
      "BER is 0.004630820684332404\n",
      "Precision: 0.18181818181818182\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf_RFC_reduced1 = RandomForestClassifier(n_estimators=100,max_depth=3, random_state=0,class_weight = {0:1,1:70})\n",
    "clf_RFC_reduced1.fit(X_training_reduced1, y_training)\n",
    "pred_RFC_reduced1 = clf_RFC_reduced1.predict(X_testing_reduced1)\n",
    "evaluate(pred_RFC_reduced1, y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1290dfda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for weight in range(1,70):\n",
    "    clf_RFC = RandomForestClassifier(n_estimators=100,max_depth=3, random_state=0,class_weight = {0:1,1:weight})\n",
    "    clf_RFC.fit(X_training, y_training)\n",
    "    pred_RFC = clf_RFC.predict(X_testing)\n",
    "    p,r = evaluate_noprint(pred_RFC, y_testing)\n",
    "    plt.scatter(r, p, color='r', marker=\".\")\n",
    "\n",
    "\n",
    "plt.title(\"PR Curve - class weight\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "#red_patch = mpatches.Patch(color='r', label='Precision')\n",
    "#plt.legend(handles=[red_patch,blue_patch],bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0.)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAEZCAYAAAC3qQ2zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/1xhxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1177dce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for weight in [1,50,100,150,200,250,300,350,400,450,500]:\n",
    "    clf_RFC_reduced1 = RandomForestClassifier(n_estimators=100,max_depth=3, random_state=0,class_weight = {0:1,1:weight})\n",
    "    clf_RFC_reduced1.fit(X_training_reduced1, y_training)\n",
    "    pred_RFC_reduced1 = clf_RFC_reduced1.predict(X_testing_reduced1)\n",
    "    p,r = evaluate_noprint(pred_RFC_reduced1, y_testing)\n",
    "    \n",
    "    plt.scatter(weight, p, color='r', marker=\".\")\n",
    "    plt.scatter(weight, r, color='b', marker=\".\", alpha=.35)\n",
    "\n",
    "\n",
    "plt.title(\"Precision & Recall - class weight\")\n",
    "plt.xlabel(\"class weight\")\n",
    "red_patch = mpatches.Patch(color='r', label='Precision')\n",
    "plt.legend(handles=[red_patch,blue_patch],bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0.)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for our training model: \n",
      "\n",
      "True positives: 5\n",
      "True negatives: 3883\n",
      "False positives: 4\n",
      "False negatives: 3\n",
      "\n",
      "Accuracy: 0.9982028241335045\n",
      "BER is 0.18801453563159254\n",
      "Precision: 0.5555555555555556\n",
      "Recall: 0.625\n"
     ]
    }
   ],
   "source": [
    "clf_LR = LogisticRegression(C=0.01)\n",
    "clf_LR.fit(X_training, y_training)\n",
    "\n",
    "pred_RFC_LR = clf_LR.predict(X_testing)\n",
    "evaluate(pred_RFC_LR, y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR = LogisticRegression(C=0.01)\n",
    "clf_LR.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556 0.625\n",
      "0.6 0.75\n",
      "0.5833333333333334 0.875\n",
      "0.4375 0.875\n",
      "0.47058823529411764 1.0\n",
      "0.4 1.0\n",
      "0.4 1.0\n",
      "0.4 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIknqzBCRJHVmiEiSOvv/mwOcNpCnV+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1293a1358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c in [0.01,0.05,0.1,0.5,1,10,100,1000]:\n",
    "    clf_LR = LogisticRegression(C=c)\n",
    "    clf_LR.fit(X_training, y_training)\n",
    "    pred_LR = clf_LR.predict(X_testing)\n",
    "    p,r = evaluate_noprint(pred_LR, y_testing)\n",
    "    print (str(p) + ' ' + str(r))\n",
    "    plt.scatter(r, p, color='r', marker=\".\")\n",
    "\n",
    "\n",
    "plt.title(\"PR Curve - C\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "#red_patch = mpatches.Patch(color='r', label='Precision')\n",
    "#plt.legend(handles=[red_patch,blue_patch],bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0.)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for weight in range(1,70):\n",
    "    clf_RFC = RandomForestClassifier(n_estimators=100,max_depth=3, random_state=0,class_weight = {0:1,1:weight})\n",
    "    clf_RFC.fit(X_training, y_training)\n",
    "    pred_RFC = clf_RFC.predict(X_testing)\n",
    "    p,r = evaluate_noprint(pred_RFC, y_testing)\n",
    "    print (str(p) + ' ' + str(r))\n",
    "    plt.scatter(r, p, color='r', marker=\".\")\n",
    "\n",
    "\n",
    "plt.title(\"PR Curve - class weight\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "#red_patch = mpatches.Patch(color='r', label='Precision')\n",
    "#plt.legend(handles=[red_patch,blue_patch],bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0.)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for our training model: \n",
      "\n",
      "True positives: 0\n",
      "True negatives: 3887\n",
      "False positives: 0\n",
      "False negatives: 8\n",
      "\n",
      "Accuracy: 0.9979460847240051\n",
      "BER is 0.5\n",
      "Precision: 0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf_svm1 = svm.SVC(C=1000,decision_function_shape='ovo',class_weight = {0:1,1:1000},random_state=2)\n",
    "clf_svm1.fit(X_training, y_training)\n",
    "pred_svm1 = clf_svm1.predict(X_testing)\n",
    "evaluate(pred_svm1, y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for our training model: \n",
      "\n",
      "True positives: 0\n",
      "True negatives: 3886\n",
      "False positives: 1\n",
      "False negatives: 8\n",
      "\n",
      "Accuracy: 0.9976893453145058\n",
      "BER is 0.5001286339078981\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf_svm2 = svm.LinearSVC(class_weight = {0:1,1:1000000}, random_state = 0)\n",
    "clf_svm2.fit(X_training, y_training)\n",
    "pred_svm2 = clf_svm2.predict(X_testing)\n",
    "evaluate(pred_svm2, y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for weight in range(1,1000000,100):\n",
    "    clf_svm2 = svm.LinearSVC(decision_function_shape='ovo',class_weight = {0:1,1:weight})\n",
    "    clf_svm2.fit(X_training, y_training)\n",
    "    pred_svm2 = clf_svm2.predict(X_testing)\n",
    "    p,r = evaluate_noprint(pred_svm2, y_testing)\n",
    "    \n",
    "    plt.scatter(weight, p, color='r', marker=\".\")\n",
    "    plt.scatter(weight, r, color='b', marker=\".\", alpha=.35)\n",
    "\n",
    "\n",
    "plt.title(\"PR Curve - class weight - LinearSVC\")\n",
    "plt.xlabel(\"class weight\")\n",
    "red_patch = mpatches.Patch(color='r', label='Precision')\n",
    "plt.legend(handles=[red_patch,blue_patch],bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0.)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votingDict = defaultdict(lambda:defaultdict(float))\n",
    "for row in voting_data.itertuples():\n",
    "    votingDict[row.Year][row.Player] = row.Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct training data for top1 prediction, use data from before 2010\n",
    "X_training_top1 = []\n",
    "y_training_top1 = []\n",
    "y_training_vote = [] #Use vote share as y labels\n",
    "X_training_vote_6 = []\n",
    "for d in data_refined:\n",
    "    year = d.Year\n",
    "    name = d.Name\n",
    "    if name[-1] == '*':\n",
    "        name = name[0:-1]\n",
    "    if year < 2010:\n",
    "        if mvps[int(d.Year)] == name:\n",
    "            y_training_top1.append(1)\n",
    "        else:\n",
    "            y_training_top1.append(0)\n",
    "        y_training_vote.append(votingDict[year][name])\n",
    "    \n",
    "        #NOTE: change features here\n",
    "        features = [d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP]\n",
    "        X_training_top1.append(features)\n",
    "        \n",
    "        features2 = [d.PER,d.TSr,d.USGr,d.WS,d.BPM,d.VORP]\n",
    "        X_training_vote_6.append(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalization, use if needed\n",
    "std_scale = preprocessing.StandardScaler().fit(X_training_top1)\n",
    "X_training_top1_std = std_scale.transform(X_training_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest regressor, for top1 prediction\n",
    "clf_RFR = RandomForestRegressor(n_estimators = 10,max_depth=3, random_state=0)\n",
    "clf_RFR.fit(X_training_top1_std, y_training_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest regressor, for top1 prediction, vote as labels\n",
    "clf_RFR_vote = RandomForestRegressor(n_estimators = 10,max_depth=2, random_state=0)\n",
    "clf_RFR_vote.fit(X_training_top1, y_training_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest regressor, for top1 prediction\n",
    "clf_RFR_vote_6 = RandomForestRegressor(n_estimators = 100,max_depth=2, random_state=0)\n",
    "clf_RFR_vote_6.fit(X_training_vote_6, y_training_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.01605433,  0.        ,\n",
       "        0.        ,  0.02358569,  0.01312634,  0.        ,  0.01323872,\n",
       "        0.04551988,  0.01305729,  0.01347416,  0.02920457,  0.43628967,\n",
       "        0.02478699,  0.        ,  0.00659142,  0.01673792,  0.03738397,\n",
       "        0.        ,  0.02432199,  0.        ,  0.        ,  0.        ,\n",
       "        0.05997888,  0.        ,  0.01445336,  0.        ,  0.01479575,\n",
       "        0.01956489,  0.        ,  0.0723487 ,  0.0069289 ,  0.02283523,\n",
       "        0.03324094,  0.01168716,  0.01789982,  0.00412356,  0.        ,\n",
       "        0.00876986,  0.        ])"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_training_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.67696037]\n",
      "    Kevin Durant has score [ 0.47684729]\n",
      "    Dwyane Wade has score [ 0.15124608]\n",
      "    Dwight Howard has score [ 0.14532172]\n",
      "    Dirk Nowitzki has score [ 0.10491665]\n",
      "predict CORRECT for year 2010\n",
      "\n",
      "2011 mvp was Derrick Rose\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.50091604]\n",
      "    Pau Gasol has score [ 0.268787]\n",
      "    Dwight Howard has score [ 0.25017855]\n",
      "    Chris Paul has score [ 0.18668957]\n",
      "    Derrick Rose has score [ 0.14168401]\n",
      "predict INCORRECT for year 2011\n",
      "\n",
      "2012 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.31489782]\n",
      "    Chris Paul has score [ 0.13438565]\n",
      "    Kevin Durant has score [ 0.10277445]\n",
      "    Manu Ginobili has score [ 0.02195681]\n",
      "    Kyrylo Fesenko has score [ 0.02195681]\n",
      "predict CORRECT for year 2012\n",
      "\n",
      "2013 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.65310419]\n",
      "    Kevin Durant has score [ 0.62166922]\n",
      "    Chris Paul has score [ 0.22453332]\n",
      "    James Harden has score [ 0.13202799]\n",
      "    Russell Westbrook has score [ 0.07831269]\n",
      "predict CORRECT for year 2013\n",
      "\n",
      "2014 mvp was Kevin Durant\n",
      "    Top 5 in our predictions are below: \n",
      "    Kevin Durant has score [ 0.6537872]\n",
      "    LeBron James has score [ 0.5453792]\n",
      "    Kevin Love has score [ 0.29403061]\n",
      "    Stephen Curry has score [ 0.14918583]\n",
      "    James Harden has score [ 0.13326448]\n",
      "predict CORRECT for year 2014\n",
      "\n",
      "2015 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    James Harden has score [ 0.65442743]\n",
      "    Stephen Curry has score [ 0.52889226]\n",
      "    Chris Paul has score [ 0.49360474]\n",
      "    Anthony Davis has score [ 0.24397669]\n",
      "    DeAndre Jordan has score [ 0.11219694]\n",
      "predict INCORRECT for year 2015\n",
      "\n",
      "2016 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Stephen Curry has score [ 0.65310419]\n",
      "    Kevin Durant has score [ 0.28103892]\n",
      "    Russell Westbrook has score [ 0.27960799]\n",
      "    LeBron James has score [ 0.2060993]\n",
      "    Kawhi Leonard has score [ 0.18898806]\n",
      "predict CORRECT for year 2016\n",
      "\n",
      "2017 mvp was Russell Westbrook\n",
      "    Top 5 in our predictions are below: \n",
      "    James Harden has score [ 0.41925154]\n",
      "    Jimmy Butler has score [ 0.22824488]\n",
      "    Rudy Gobert has score [ 0.20766525]\n",
      "    Kawhi Leonard has score [ 0.18898806]\n",
      "    Russell Westbrook has score [ 0.16234412]\n",
      "predict INCORRECT for year 2017\n",
      "\n",
      "Total correct are 5 out of 8\n"
     ]
    }
   ],
   "source": [
    "#Use 6 features, vote as y labels\n",
    "#Construct testing data for top1 prediction\n",
    "X_testing_vote_6 = {}\n",
    "for i in range(2010,2018):\n",
    "    X1 = []\n",
    "    for d in data_refined:\n",
    "        year = d.Year\n",
    "        if year == i:\n",
    "            tmp2 = [d.Name,d.PER,d.TSr,d.USGr,d.WS,d.BPM,d.VORP]\n",
    "            X1.append(tmp2)\n",
    "    X_testing_vote_6[i] = X1\n",
    "    \n",
    "correct = 0\n",
    "for year in range(2010,2018):\n",
    "    #X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "    X = X_testing_vote_6[year]\n",
    "    print (str(year) + ' mvp was ' + str(mvps[year]))\n",
    "    for idx in range(len(X)):\n",
    "        pred = clf_RFR_vote_6.predict(X[idx][1:])\n",
    "        X[idx] = [pred] + X[idx] \n",
    "    X.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "    tops = [X[0][1]]\n",
    "    for idx in range(1,len(X)):\n",
    "        if X[idx][0] == X[0][0]:\n",
    "            tops.append(X[idx][1])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print ('    Top 5 in our predictions are below: ')\n",
    "    for i in range(5):\n",
    "        print ('    ' + str(X[i][1]) + ' has score ' + str(X[i][0]))\n",
    "    if mvps[year] in tops:\n",
    "        correct += 1\n",
    "        print ('predict CORRECT for year ' + str(year))\n",
    "    else:\n",
    "        print ('predict INCORRECT for year ' + str(year))\n",
    "    print ()\n",
    "print ('Total correct are ' + str(correct) + ' out of 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 mvp was LeBron James\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must  match the input. Model n_features is 20 and  input n_features is 44 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-632-cb70ca1f471b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' mvp was '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_RFR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \"\"\"\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    317\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[0;34m\" match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\" input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must  match the input. Model n_features is 20 and  input n_features is 44 "
     ]
    }
   ],
   "source": [
    "#Construct testing data for top1 prediction\n",
    "X_testing_top1 = {}\n",
    "for i in range(2010,2018):\n",
    "    X = []\n",
    "    X1 = []\n",
    "    for d in data_refined:\n",
    "        year = d.Year\n",
    "        if year == i:\n",
    "            tmp = [d.Name,d.Games,d.MP,d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "            X.append(tmp)\n",
    "            tmp2 = [d.PER,d.TSr,d.USGr,d.WS,d.BPM,d.VORP]\n",
    "            X1.append(tmp2)\n",
    "    X_testing_top1[i] = X\n",
    "    \n",
    "correct = 0\n",
    "for year in range(2010,2018):\n",
    "    #X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "    X = X_testing_top1[year]\n",
    "    print (str(year) + ' mvp was ' + str(mvps[year]))\n",
    "    for idx in range(len(X)):\n",
    "        pred = clf_RFR.predict(X[idx][1:])\n",
    "        X[idx] = [pred] + X[idx] \n",
    "    X.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "    tops = [X[0][1]]\n",
    "    for idx in range(1,len(X)):\n",
    "        if X[idx][0] == X[0][0]:\n",
    "            tops.append(X[idx][1])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print ('    Top 5 in our predictions are below: ')\n",
    "    for i in range(5):\n",
    "        print ('    ' + str(X[i][1]) + ' has score ' + str(X[i][0]))\n",
    "    if mvps[year] in tops:\n",
    "        correct += 1\n",
    "        print ('predict CORRECT for year ' + str(year))\n",
    "    else:\n",
    "        print ('predict INCORRECT for year ' + str(year))\n",
    "    print ()\n",
    "print ('Total correct are ' + str(correct) + ' out of 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.66782581]\n",
      "    James Harden has score [ 0.53361529]\n",
      "    Giannis Antetokounmpo has score [ 0.15558399]\n",
      "    Anthony Davis has score [ 0.13832094]\n",
      "    Stephen Curry has score [ 0.04051557]\n",
      "    LaMarcus Aldridge has score [ 0.01772965]\n",
      "    Damian Lillard has score [ 0.01772965]\n",
      "    Joakim Noah has score [ 0.01274991]\n",
      "    Matt Costello has score [ 0.01117097]\n",
      "    Kyrie Irving has score [ 0.00610175]\n",
      "    Russell Westbrook has score [ 0.00346977]\n",
      "    Paul George has score [ 0.00346977]\n",
      "    Jayson Tatum has score [ 0.00346977]\n",
      "    Andre Drummond has score [ 0.00346977]\n",
      "    Al Horford has score [ 0.00346977]\n",
      "    Vince Hunter has score [ 0.00168143]\n",
      "    Kyle Singler has score [ 0.00168143]\n",
      "    Jamil Wilson has score [ 0.00168143]\n",
      "    Jack Cooley has score [ 0.00168143]\n",
      "    Zhou Qi has score [ 0.00010248]\n",
      "    Zaza Pachulia has score [ 0.00010248]\n",
      "    Zach Randolph has score [ 0.00010248]\n",
      "    Zach Collins has score [ 0.00010248]\n",
      "    Yogi Ferrell has score [ 0.00010248]\n",
      "    Wilson Chandler has score [ 0.00010248]\n",
      "    Willy Hernangomez has score [ 0.00010248]\n",
      "    Willie Reed has score [ 0.00010248]\n",
      "    Willie Cauley-Stein has score [ 0.00010248]\n",
      "    Will Barton has score [ 0.00010248]\n",
      "    Wesley Matthews has score [ 0.00010248]\n"
     ]
    }
   ],
   "source": [
    "#Predict 2018 MVP\n",
    "#Construct testing data for top1 prediction\n",
    "X_testing_2018 = []\n",
    "for row in data2018.itertuples():\n",
    "    tmp = [row.PER,row[11],row[12],row.FTr,row[14],row[15],row[16],row[17],row[18],row[19],row[20],row[21],row.OWS,row.DWS,row.WS,row[26],row.OBPM,row.DBPM,row.BPM,row.VORP]\n",
    "    #tmp = [d.Player,d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "    X_testing_2018.append(tmp)\n",
    "    \n",
    "#X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "std_scale = preprocessing.StandardScaler().fit(X_testing_2018)\n",
    "X_testing_2018_std = std_scale.transform(X_testing_2018)\n",
    "\n",
    "i = 0\n",
    "X_testing_2018_stdd = []\n",
    "for row in data2018.itertuples():\n",
    "    tp = [row.Player]\n",
    "    for item in X_testing_2018_std[i]:\n",
    "        tp.append(item)\n",
    "    X_testing_2018_stdd.append(tp)\n",
    "    i += 1\n",
    "    \n",
    "for idx in range(len(X_testing_2018_stdd)):\n",
    "    pred = clf_RFR.predict(X_testing_2018_stdd[idx][1:])\n",
    "    X_testing_2018_stdd[idx] = [pred] + X_testing_2018_stdd[idx] \n",
    "X_testing_2018_stdd.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "tops = [X_testing_2018_stdd[0][1]]\n",
    "for idx in range(1,len(X_testing_2018_stdd)):\n",
    "    if X_testing_2018_stdd[idx][0] == X_testing_2018_stdd[0][0]:\n",
    "        tops.append(X_testing_2018_stdd[idx][1])\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "print ('    Top 5 in our predictions are below: ')\n",
    "for i in range(30):\n",
    "    print ('    ' + str(X_testing_2018_stdd[i][1]) + ' has score ' + str(X_testing_2018_stdd[i][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.49943117e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.98633521e-02,   1.73348815e-02,   1.25643629e-02,\n",
       "         5.61053922e-02,   2.09824211e-02,   9.59803587e-03,\n",
       "         1.33859152e-02,   4.59987631e-02,   2.13614855e-04,\n",
       "         7.37386062e-02,   6.31875883e-02,   4.29524355e-01,\n",
       "         3.12267920e-02,   0.00000000e+00,   3.15558016e-02,\n",
       "         3.69840119e-02,   4.27417949e-02])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.68142562]), 'Nikola Jokic', 24.699999999999999, 0.245, 9.6999999999999993, 0.245, 20.0, 24.899999999999999, 2.2999999999999998, 1.8, 14.699999999999999, 21.699999999999999, 2.0, 0.90000000000000002, 2.0, 0.90000000000000002, 2.8999999999999999, 7.2000000000000002, 4.5999999999999996, 2.6000000000000001, 7.2000000000000002, 1.3999999999999999]\n"
     ]
    }
   ],
   "source": [
    "print (X_testing_2018[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.55332952]\n",
      "    Kevin Durant has score [ 0.44584881]\n",
      "    Dwyane Wade has score [ 0.12847746]\n",
      "    Dwight Howard has score [ 0.12847746]\n",
      "    Dirk Nowitzki has score [ 0.11177297]\n",
      "predict CORRECT for year 2010\n",
      "\n",
      "2011 mvp was Derrick Rose\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.44584881]\n",
      "    Pau Gasol has score [ 0.24501943]\n",
      "    Dwight Howard has score [ 0.23008413]\n",
      "    Chris Paul has score [ 0.13587438]\n",
      "    Dwyane Wade has score [ 0.12847746]\n",
      "predict INCORRECT for year 2011\n",
      "\n",
      "2012 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.30817173]\n",
      "    Chris Paul has score [ 0.17181606]\n",
      "    Kevin Durant has score [ 0.11177297]\n",
      "    Tim Duncan has score [ 0.00619477]\n",
      "    Russell Westbrook has score [ 0.00619477]\n",
      "predict CORRECT for year 2012\n",
      "\n",
      "2013 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [ 0.55332952]\n",
      "    Kevin Durant has score [ 0.55332952]\n",
      "    Chris Paul has score [ 0.17921299]\n",
      "    James Harden has score [ 0.12847746]\n",
      "    Russell Westbrook has score [ 0.0949199]\n",
      "predict CORRECT for year 2013\n",
      "\n",
      "2014 mvp was Kevin Durant\n",
      "    Top 5 in our predictions are below: \n",
      "    Kevin Durant has score [ 0.5953247]\n",
      "    LeBron James has score [ 0.51629985]\n",
      "    Kevin Love has score [ 0.19970203]\n",
      "    Stephen Curry has score [ 0.12847746]\n",
      "    James Harden has score [ 0.12847746]\n",
      "predict CORRECT for year 2014\n",
      "\n",
      "2015 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Stephen Curry has score [ 0.55664383]\n",
      "    Chris Paul has score [ 0.55664383]\n",
      "    James Harden has score [ 0.50418147]\n",
      "    Anthony Davis has score [ 0.21116301]\n",
      "    DeAndre Jordan has score [ 0.12847746]\n",
      "predict CORRECT for year 2015\n",
      "\n",
      "2016 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Stephen Curry has score [ 0.5936735]\n",
      "    Kevin Durant has score [ 0.34851571]\n",
      "    Kawhi Leonard has score [ 0.17181606]\n",
      "    Russell Westbrook has score [ 0.17086887]\n",
      "    LeBron James has score [ 0.12847746]\n",
      "predict CORRECT for year 2016\n",
      "\n",
      "2017 mvp was Russell Westbrook\n",
      "    Top 5 in our predictions are below: \n",
      "    James Harden has score [ 0.34463013]\n",
      "    Kawhi Leonard has score [ 0.17181606]\n",
      "    Rudy Gobert has score [ 0.15466239]\n",
      "    Jimmy Butler has score [ 0.13587438]\n",
      "    Stephen Curry has score [ 0.12847746]\n",
      "predict INCORRECT for year 2017\n",
      "\n",
      "Total correct are 6 out of 8\n"
     ]
    }
   ],
   "source": [
    "#Random Forest regressor, all features\n",
    "#Construct testing data for top1 prediction\n",
    "X_testing_top1 = {}\n",
    "for i in range(2010,2018):\n",
    "    X = []\n",
    "    for d in data_refined:\n",
    "        year = d.Year\n",
    "        if year == i:\n",
    "            tmp = [d.Name,d.Games,d.MP,d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "            X.append(tmp)\n",
    "            y_training_vote.append(votingDict[year][d.Name])\n",
    "    X_testing_top1[i] = X\n",
    "    \n",
    "correct = 0\n",
    "for year in range(2010,2018):\n",
    "    #X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "    X = X_testing_top1[year]\n",
    "    print (str(year) + ' mvp was ' + str(mvps[year]))\n",
    "    for idx in range(len(X)):\n",
    "        pred = clf_RFR_vote.predict(X[idx][1:])\n",
    "        X[idx] = [pred] + X[idx] \n",
    "    X.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "    tops = [X[0][1]]\n",
    "    for idx in range(1,len(X)):\n",
    "        if X[idx][0] == X[0][0]:\n",
    "            tops.append(X[idx][1])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print ('    Top 5 in our predictions are below: ')\n",
    "    for i in range(5):\n",
    "        print ('    ' + str(X[i][1]) + ' has score ' + str(X[i][0]))\n",
    "    if mvps[year] in tops:\n",
    "        correct += 1\n",
    "        print ('predict CORRECT for year ' + str(year))\n",
    "    else:\n",
    "        print ('predict INCORRECT for year ' + str(year))\n",
    "    print ()\n",
    "print ('Total correct are ' + str(correct) + ' out of 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66500000000000004, 0.0, 0.0, 0.0090000000000000011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068000000000000005, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print (y_training_vote[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_training_top1_std = std_scale.transform(X_training_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svr = SVR()\n",
    "clf_svr.fit(X_training_top1, y_training_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    Ryan Bowen has score [ 0.1035583]\n",
      "    Trey Gilder has score [ 0.10355812]\n",
      "    LeBron James has score [ 0.10355711]\n",
      "    Dwight Howard has score [ 0.10355369]\n",
      "    Kevin Durant has score [ 0.10354947]\n",
      "predict INCORRECT for year 2010\n",
      "\n",
      "2011 mvp was Derrick Rose\n",
      "    Top 5 in our predictions are below: \n",
      "    Marcus Banks has score [ 0.10355839]\n",
      "    Dwight Howard has score [ 0.10355424]\n",
      "    Bobby Simmons has score [ 0.10355002]\n",
      "    Hassan Whiteside has score [ 0.10354991]\n",
      "    LeBron James has score [ 0.1035498]\n",
      "predict INCORRECT for year 2011\n",
      "\n",
      "2012 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    Keith Benson has score [ 0.10354587]\n",
      "    Hamady N'Diaye has score [ 0.1035442]\n",
      "    Brian Skinner has score [ 0.10354279]\n",
      "    Dan Gadzuric has score [ 0.10354048]\n",
      "    Kyrylo Fesenko has score [ 0.10354021]\n",
      "predict INCORRECT for year 2012\n",
      "\n",
      "2013 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    Darko Milicic has score [ 0.10355788]\n",
      "    Julyan Stone has score [ 0.10355629]\n",
      "    LeBron James has score [ 0.10355561]\n",
      "    Solomon Jones has score [ 0.10355504]\n",
      "    Darius Johnson-Odom has score [ 0.10355475]\n",
      "predict INCORRECT for year 2013\n",
      "\n",
      "2014 mvp was Kevin Durant\n",
      "    Top 5 in our predictions are below: \n",
      "    DeAndre Liggins has score [ 0.10355847]\n",
      "    Andris Biedrins has score [ 0.10355847]\n",
      "    Dexter Pittman has score [ 0.10355843]\n",
      "    Josh Childress has score [ 0.10355814]\n",
      "    Kevin Durant has score [ 0.1035569]\n",
      "predict INCORRECT for year 2014\n",
      "\n",
      "2015 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Jerrelle Benimon has score [ 0.10355847]\n",
      "    Sim Bhullar has score [ 0.10355847]\n",
      "    Tyrus Thomas has score [ 0.10355814]\n",
      "    Eric Moreland has score [ 0.10355797]\n",
      "    Stephen Curry has score [ 0.10355669]\n",
      "predict INCORRECT for year 2015\n",
      "\n",
      "2016 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Stephen Curry has score [ 0.10355839]\n",
      "    Rakeem Christmas has score [ 0.10355746]\n",
      "    James Harden has score [ 0.10355615]\n",
      "    Russell Westbrook has score [ 0.10355333]\n",
      "    Sam Dekker has score [ 0.10355324]\n",
      "predict CORRECT for year 2016\n",
      "\n",
      "2017 mvp was Russell Westbrook\n",
      "    Top 5 in our predictions are below: \n",
      "    Danuel House has score [ 0.10355841]\n",
      "    Jarnell Stokes has score [ 0.10355836]\n",
      "    Russell Westbrook has score [ 0.10355835]\n",
      "    James Harden has score [ 0.10355825]\n",
      "    Stephen Curry has score [ 0.10355615]\n",
      "predict INCORRECT for year 2017\n",
      "\n",
      "Total correct are 1 out of 8\n"
     ]
    }
   ],
   "source": [
    "#SVR\n",
    "#Construct testing data for top1 prediction\n",
    "X_testing_top1 = {}\n",
    "for i in range(2010,2018):\n",
    "    X = []\n",
    "    for d in data_refined:\n",
    "        year = d.Year\n",
    "        if year == i:\n",
    "            tmp = [d.Name,d.Games,d.MP,d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "            X.append(tmp)\n",
    "    X_testing_top1[i] = X\n",
    "\n",
    "correct = 0\n",
    "for year in range(2010,2018):\n",
    "    #X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "    X = X_testing_top1[year]\n",
    "    print (str(year) + ' mvp was ' + str(mvps[year]))\n",
    "    for idx in range(len(X)):\n",
    "        pred = clf_svr.predict(std_scale.transform(X[idx][1:]))\n",
    "        X[idx] = [pred] + X[idx] \n",
    "    X.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "    tops = [X[0][1]]\n",
    "    for idx in range(1,len(X)):\n",
    "        if X[idx][0] == X[0][0]:\n",
    "            tops.append(X[idx][1])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print ('    Top 5 in our predictions are below: ')\n",
    "    for i in range(5):\n",
    "        print ('    ' + str(X[i][1]) + ' has score ' + str(X[i][0]))\n",
    "    if mvps[year] in tops:\n",
    "        correct += 1\n",
    "        print ('predict CORRECT for year ' + str(year))\n",
    "    else:\n",
    "        print ('predict INCORRECT for year ' + str(year))\n",
    "    print ()\n",
    "print ('Total correct are ' + str(correct) + ' out of 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR = LogisticRegression()\n",
    "clf_LR.fit(X_training_top1, y_training_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_training_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [1]\n",
      "    Kevin Durant has score [1]\n",
      "    Zydrunas Ilgauskas has score [0]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Yi Jianlian has score [0]\n",
      "    Yakhouba Diawara has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "    Willie Green has score [0]\n",
      "    Will Conroy has score [0]\n",
      "predict CORRECT for year 2010\n",
      "\n",
      "2011 mvp was Derrick Rose\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [1]\n",
      "    Derrick Rose has score [1]\n",
      "    Zydrunas Ilgauskas has score [0]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Zabian Dowdell has score [0]\n",
      "    Yi Jianlian has score [0]\n",
      "    Yao Ming has score [0]\n",
      "    Xavier Henry has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "predict CORRECT for year 2011\n",
      "\n",
      "2012 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [1]\n",
      "    Kevin Durant has score [1]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Yi Jianlian has score [0]\n",
      "    Xavier Silas has score [0]\n",
      "    Xavier Henry has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "    Willie Green has score [0]\n",
      "    Will Bynum has score [0]\n",
      "predict CORRECT for year 2012\n",
      "\n",
      "2013 mvp was LeBron James\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [1]\n",
      "    Kevin Durant has score [1]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Xavier Henry has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "    Willie Green has score [0]\n",
      "    Will Conroy has score [0]\n",
      "    Will Bynum has score [0]\n",
      "    Will Barton has score [0]\n",
      "predict CORRECT for year 2013\n",
      "\n",
      "2014 mvp was Kevin Durant\n",
      "    Top 5 in our predictions are below: \n",
      "    LeBron James has score [1]\n",
      "    Kevin Durant has score [1]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Xavier Henry has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "    Willie Green has score [0]\n",
      "    Will Bynum has score [0]\n",
      "    Will Barton has score [0]\n",
      "    Wesley Matthews has score [0]\n",
      "predict CORRECT for year 2014\n",
      "\n",
      "2015 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Stephen Curry has score [1]\n",
      "    James Harden has score [1]\n",
      "    Zoran Dragic has score [0]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Zach LaVine has score [0]\n",
      "    Xavier Henry has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "    Willie Green has score [0]\n",
      "    Will Cherry has score [0]\n",
      "predict CORRECT for year 2015\n",
      "\n",
      "2016 mvp was Stephen Curry\n",
      "    Top 5 in our predictions are below: \n",
      "    Stephen Curry has score [1]\n",
      "    Russell Westbrook has score [1]\n",
      "    Kevin Durant has score [1]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Zach LaVine has score [0]\n",
      "    Xavier Munford has score [0]\n",
      "    Willie Reed has score [0]\n",
      "    Willie Cauley-Stein has score [0]\n",
      "    Will Barton has score [0]\n",
      "predict CORRECT for year 2016\n",
      "\n",
      "2017 mvp was Russell Westbrook\n",
      "    Top 5 in our predictions are below: \n",
      "    Russell Westbrook has score [1]\n",
      "    James Harden has score [1]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Zach LaVine has score [0]\n",
      "    Yogi Ferrell has score [0]\n",
      "    Wilson Chandler has score [0]\n",
      "    Willy Hernangomez has score [0]\n",
      "    Willie Reed has score [0]\n",
      "    Willie Cauley-Stein has score [0]\n",
      "predict CORRECT for year 2017\n",
      "\n",
      "Total correct are 8 out of 8\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "#Construct testing data for top1 prediction\n",
    "X_testing_top1 = {}\n",
    "for i in range(2010,2018):\n",
    "    X = []\n",
    "    for d in data_refined:\n",
    "        year = d.Year\n",
    "        if year == i:\n",
    "            tmp = [d.Name,d.Games,d.MP,d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "            X.append(tmp)\n",
    "    X_testing_top1[i] = X\n",
    "\n",
    "correct = 0\n",
    "for year in range(2010,2018):\n",
    "    #X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "    X = X_testing_top1[year]\n",
    "    print (str(year) + ' mvp was ' + str(mvps[year]))\n",
    "    for idx in range(len(X)):\n",
    "        pred = clf_LR.predict(X[idx][1:])\n",
    "        X[idx] = [pred] + X[idx] \n",
    "    X.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "    tops = [X[0][1]]\n",
    "    for idx in range(1,len(X)):\n",
    "        if X[idx][0] == X[0][0]:\n",
    "            tops.append(X[idx][1])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print ('    Top 5 in our predictions are below: ')\n",
    "    for i in range(10):\n",
    "        print ('    ' + str(X[i][1]) + ' has score ' + str(X[i][0]))\n",
    "    if mvps[year] in tops:\n",
    "        correct += 1\n",
    "        print ('predict CORRECT for year ' + str(year))\n",
    "    else:\n",
    "        print ('predict INCORRECT for year ' + str(year))\n",
    "    print ()\n",
    "print ('Total correct are ' + str(correct) + ' out of 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Top 5 in our predictions are below: \n",
      "    Zhou Qi has score [0]\n",
      "    Zaza Pachulia has score [0]\n",
      "    Zach Randolph has score [0]\n",
      "    Zach Collins has score [0]\n",
      "    Yogi Ferrell has score [0]\n"
     ]
    }
   ],
   "source": [
    "#LR, 2018 MVP prediction\n",
    "#Construct testing data for top1 prediction\n",
    "X_testing_2018 = []\n",
    "for row in data2018.itertuples():\n",
    "    tmp = [row.Player,row.PER,row[11],row[12],row.FTr,row[14],row[15],row[16],row[17],row[18],row[19],row[20],row[21],row.OWS,row.DWS,row.WS,row[26],row.OBPM,row.DBPM,row.BPM,row.VORP]\n",
    "    #tmp = [d.Player,d.PER,d.TSr,d.ThreePAr,d.FTRate,d.ORBr,d.DRBr,d.TRBr,d.ASTr,d.STLr,d.BLKr,d.TOVr,d.USGr,d.OWS,d.DWS,d.WS,d.WSper48,d.OBPM,d.DBPM,d.BPM,d.VORP,d.FG,d.FGA,d.FGr,d.ThreeP,d.ThreePA,d.ThreePr,d.TwoP,d.TwoPA,d.TwoPr,d.eFGr,d.FT,d.FTA,d.FTr,d.ORB,d.DRB,d.TRB,d.AST,d.STL,d.BLK,d.TOV,d.PF,d.PTS]\n",
    "    X_testing_2018.append(tmp)\n",
    "    \n",
    "#X is all players' data of that year. Make prediction on each then sort in descending order\n",
    "\n",
    "\n",
    "for idx in range(len(X_testing_2018)):\n",
    "    pred = clf_LR.predict(X_testing_2018[idx][1:])\n",
    "    X_testing_2018[idx] = [pred] + X_testing_2018[idx] \n",
    "X_testing_2018.sort(reverse = True)\n",
    "    \n",
    "    #in case of a tie, get all the top ranking players\n",
    "tops = [X_testing_2018[0][1]]\n",
    "for idx in range(1,len(X_testing_2018)):\n",
    "    if X_testing_2018[idx][0] == X_testing_2018[0][0]:\n",
    "        tops.append(X_testing_2018[idx][1])\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "print ('    Top 5 in our predictions are below: ')\n",
    "for i in range(5):\n",
    "    print ('    ' + str(X_testing_2018[i][1]) + ' has score ' + str(X_testing_2018[i][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12122852, -1.24469802, -1.15701047, -0.73808842, -0.69939502,\n",
       "        -0.70253132,  1.21371234,  0.02361416, -1.54105108, -0.28496401,\n",
       "        -0.14495539, -0.06552083,  0.01463959,  0.50993109,  0.60230467,\n",
       "        -0.01790966,  0.13569576,  0.22281577,  0.38421771, -0.27187013]])"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
